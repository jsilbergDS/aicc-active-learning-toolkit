{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U2A93U8uTO7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from active_embedder import *\n",
    "from prob_cover import *\n",
    "from data_labeler import *\n",
    "from resnet_verification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning for Classification Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPw6UfrmTPi-"
   },
   "source": [
    "Why we made this: Active Learning algorithms such as ProbCover have achieved state of the art results, and even made improvements over Self-Supervised and Semi-Supervised techniques. However, most of these results are in simualted environments: the datasets were actually labelled, but the labels were hidden from the model until the Active Learning \"oracle\" unhid them. We wanted to make Active Learning work for you -- dear Reader with a truly unlabelled dataset, by providing a full-service workflow. You start with an image folder of unlabelled data, and use this Toolkit to generate embeddings, select the examples to label, and save the labels. \n",
    "\n",
    "When to use this: This toolkit focuses on the Cold Start problem. Many Active Learning frameworks, such as weakly supervised or semi-supervised learning rely on an \"initial set\" of labelled examples and work to propogate those labels to unlabelled examples. The harder problem is when ALL your data is unlabelled. Where do you even know where to start labelling? That's where this toolkit comes in. We'll help you label as many examples as possible to get a working classifier, and provide guidance on when you can stop labelling\n",
    "\n",
    "How to use the toolkit: Unfortunately, the interactivity of this notebook tends to slow way down on Colab. We recommend cloning this repo and running a jupyter notebook locally. \n",
    "\n",
    "The steps are as follows:\n",
    "\n",
    "### [Part 1: Prep work](#part_1)\n",
    "\n",
    "Enter the root directory where your images are stored in the cells below. The cell after that will find all images in the folder, so don't worry about file naming and folder structure\n",
    "\n",
    "### [Part 2: Create Embeddings](#part_2)\n",
    "\n",
    "Specify or create Embeddings. All our Active Learning algorithms require a good embedding space as a prerequisite. If you already have self-supervised embeddings from your data, simply enter where the npy or pth file is stored. If you don't have embeddings, you have three options -- using the forward pass on a pre-trained VGG model to generate embeddings, using the forward pass on a self-supervised ResNet to generate embeddings, or fine-tuning a self-supervised model on your dataset. The first two will run quickly, the second will likely take about a day to run. \n",
    "\n",
    "### [Part 3: Label your examples with Active Learning](#part_3)\n",
    "\n",
    "Use your embeddings to select examples to label. Instantiate a class of our Active Learners as specified below, and it will generate a list of examples to label. The step will save a data manifest for your future use\n",
    "\n",
    "### [Part_4: Test a model](#part_4)\n",
    "\n",
    "Use those labels to build a DataLoader. You're now ready to train a classifier that should have maximum performance per labelled example!\n",
    "\n",
    "A final note before we begin: To keep this notebook organized, most length functions (e.g., our Active Learner classes, our visualization classes) are imported. However, the whole reason we made this a notebook instead of a GUI is so that you can see them, inspect them, and create your own classes that may well improve on anything we did. At your leisure, browse the rest of the code in this repo to understand how these algorithms maximize performance, and modify to your heart's delight. \n",
    "\n",
    "Sounds good? Let's get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"part_1\"> Part 1 <a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VZ4N3MzV7ZM"
   },
   "source": [
    "Enter the root directory within which all images are stored. The format of this folder doesn't matter, but note that ALL images within the folder you specify will be added to your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Lp3P4jDZV4Jp"
   },
   "outputs": [],
   "source": [
    "image_dir = \"/deep/u/jsilberg/Brazil_hard_detections_1024_2500\" # ENTER IMAGE FOLDER HERE\n",
    "image_size = 256  # ENTER IMAGE HEIGHT OR WIDTH HERE (ASSUMED TO BE THE SAME)\n",
    "image_format = \".jpg\"  # SPECIFY FILE TYPE, WE SUPPORT .jpg, .jpeg, OR .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OQ8DRv7hWzVv"
   },
   "outputs": [],
   "source": [
    "image_list = []\n",
    "for root, dirs, files in os.walk(image_dir, topdown=True):\n",
    "   for name in files:\n",
    "      if name[-4:]==image_format:\n",
    "        image_list.append(os.path.join(root,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Xo4o_6Hcwh2"
   },
   "source": [
    "If you already have embeddings for your images, please enter the location of the .npy or .pth below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zH8FucwNcvry"
   },
   "outputs": [],
   "source": [
    "embeddings_loc = None # REPLACE NONE WITH A PATH TO YOUR EMBEDDINGS IF YOU HAVE IT, DO NOTHING IF YOU WANT US TO CREATE EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id =\"part_2\">Part 2: Create Embeddings<a>\n",
    "\n",
    "**If you already have embeddings, skip ahead to [Part 3](#part_3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_path = \"embeddings_simclr.pth\" # ENTER WHERE YOU WANT THE EMBEDDINGS TO BE SAVED ENDING IN \".pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCXhINJoc9tA"
   },
   "source": [
    "If you don't have embeddings, we'll create them for you. Choose from the following options:\n",
    "\n",
    "If you are working with normal images (e.g., images at ground-level) use one of the following\n",
    "\n",
    "1: VGG pre-trained on ImageNet (fast)\n",
    "\n",
    "2: ResNet pre-trained on SimCLR (medium, requires large download)\n",
    "\n",
    "3: Fine-tuning SimCLR on your data (runtime depends on the number of images in your dataset, but budget up to day for a dataset of 50000+ images)\n",
    "\n",
    "If you are working with remote sensing (e.g., satellite images) use one of the following:\n",
    "\n",
    "4: VGG pre-trained on fMOW (fast)\n",
    "\n",
    "5: Frozen SatMAE (medium, requires large download)\n",
    "\n",
    "6: Fine-tune SatMAE (runtime is around a day usually)\n",
    "\n",
    "If you are working with medical imagery (e.g., X-rays), use one of the following:\n",
    "\n",
    "7: VGG pre-trained on SOMETHING\n",
    "\n",
    "8: Frozen medical SimCLR\n",
    "\n",
    "9: Fine-tune on SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JKF-tPCFc9ZY"
   },
   "outputs": [],
   "source": [
    "embedding_option = 2 # Replace with the number of the option you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomResizedCrop(size=224),\n",
    "                                          transforms.RandomApply([\n",
    "                                              transforms.ColorJitter(brightness=0.5,\n",
    "                                                                     contrast=0.5,\n",
    "                                                                     saturation=0.5,\n",
    "                                                                     hue=0.1)\n",
    "                                          ], p=0.8),\n",
    "                                          transforms.RandomGrayscale(p=0.2),\n",
    "                                          transforms.GaussianBlur(kernel_size=9),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.5,), (0.5,))\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMdP4CULkMqw"
   },
   "source": [
    "If you chose option 2, 5, or 8, you must provide a path to where you want the model stored, and a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Embedder(image_list,image_size,embedding_option,transform=contrast_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_transform = transforms.Compose([transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.5,), (0.5,))\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted have the shape: torch.Size([557, 128])\n"
     ]
    }
   ],
   "source": [
    "embeddings = embedder.get_embeddings(embeddings_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will save the embeddings to disk just to make sure we have them saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings,embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_loc = embeddings_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=part_3>Part 3: Active Learning<a>\n",
    "    \n",
    "#### If you already created manifests of your data, skip to [Part 4](#part_4)\n",
    "\n",
    "Please provide a list of the classes in your data and how many examples you want to label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we will create an \"Active Learner\" instance, which provides a reference to the list of \"best\" examples to label. First enter your set of mutually exclusive labels, and let's decide how many examples we want to label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = [\"oil\",\"water\",\"wind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_to_label = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have implemented two kinds of Active Learners. The first, ProbCover, comes from <a href='https://arxiv.org/abs/2205.11320'>Active Learning Through a Covering Lens</a> and minimizes the 1-NN error for a given labeling budget. The second, CoverNN, is our own, and minimizes the likelihood that a knn-graph contains images of difference classes. Run ONE of the following two cells, based on which active learner you want to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_labels = ProbCover(save_dir=\"\",image_list=image_list,embeddings_loc=embeddings_loc,num_classes=len(labels_list),k=30,input_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data...\n",
      "Start constructing graph using k=30\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([32, 501])\n",
      "torch.Size([21, 501])\n",
      "Finished constructing graph using k=30\n",
      "Graph contains 15030 edges.\n"
     ]
    }
   ],
   "source": [
    "prob_labels = CoverNN(save_dir=\"\",image_list=image_list,embeddings_loc=embeddings_loc,num_classes=len(labels_list),k=30,input_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start selecting 50 samples.\n",
      "Iteration is 0.\tMin distance is 0.041.\tCoverage is 0.000\n",
      "Iteration is 1.\tMin distance is 0.054.\tCoverage is 0.060\n",
      "Iteration is 2.\tMin distance is 0.057.\tCoverage is 0.088\n",
      "Iteration is 3.\tMin distance is 0.058.\tCoverage is 0.098\n",
      "Iteration is 4.\tMin distance is 0.058.\tCoverage is 0.118\n",
      "Iteration is 5.\tMin distance is 0.060.\tCoverage is 0.122\n",
      "Iteration is 6.\tMin distance is 0.061.\tCoverage is 0.126\n",
      "Iteration is 7.\tMin distance is 0.064.\tCoverage is 0.158\n",
      "Iteration is 8.\tMin distance is 0.064.\tCoverage is 0.168\n",
      "Iteration is 9.\tMin distance is 0.064.\tCoverage is 0.172\n",
      "Iteration is 10.\tMin distance is 0.065.\tCoverage is 0.180\n",
      "Iteration is 11.\tMin distance is 0.065.\tCoverage is 0.240\n",
      "Iteration is 12.\tMin distance is 0.066.\tCoverage is 0.287\n",
      "Iteration is 13.\tMin distance is 0.066.\tCoverage is 0.289\n",
      "Iteration is 14.\tMin distance is 0.067.\tCoverage is 0.297\n",
      "Iteration is 15.\tMin distance is 0.067.\tCoverage is 0.301\n",
      "Iteration is 16.\tMin distance is 0.068.\tCoverage is 0.317\n",
      "Iteration is 17.\tMin distance is 0.068.\tCoverage is 0.325\n",
      "Iteration is 18.\tMin distance is 0.068.\tCoverage is 0.359\n",
      "Iteration is 19.\tMin distance is 0.068.\tCoverage is 0.371\n",
      "Iteration is 20.\tMin distance is 0.068.\tCoverage is 0.397\n",
      "Iteration is 21.\tMin distance is 0.069.\tCoverage is 0.401\n",
      "Iteration is 22.\tMin distance is 0.069.\tCoverage is 0.427\n",
      "Iteration is 23.\tMin distance is 0.069.\tCoverage is 0.457\n",
      "Iteration is 24.\tMin distance is 0.069.\tCoverage is 0.463\n",
      "Iteration is 25.\tMin distance is 0.069.\tCoverage is 0.483\n",
      "Iteration is 26.\tMin distance is 0.069.\tCoverage is 0.491\n",
      "Iteration is 27.\tMin distance is 0.070.\tCoverage is 0.509\n",
      "Iteration is 28.\tMin distance is 0.070.\tCoverage is 0.521\n",
      "Iteration is 29.\tMin distance is 0.070.\tCoverage is 0.553\n",
      "Iteration is 30.\tMin distance is 0.070.\tCoverage is 0.565\n",
      "Iteration is 31.\tMin distance is 0.070.\tCoverage is 0.575\n",
      "Iteration is 32.\tMin distance is 0.070.\tCoverage is 0.583\n",
      "Iteration is 33.\tMin distance is 0.070.\tCoverage is 0.585\n",
      "Iteration is 34.\tMin distance is 0.071.\tCoverage is 0.593\n",
      "Iteration is 35.\tMin distance is 0.071.\tCoverage is 0.609\n",
      "Iteration is 36.\tMin distance is 0.071.\tCoverage is 0.623\n",
      "Iteration is 37.\tMin distance is 0.071.\tCoverage is 0.629\n",
      "Iteration is 38.\tMin distance is 0.071.\tCoverage is 0.631\n",
      "Iteration is 39.\tMin distance is 0.071.\tCoverage is 0.643\n",
      "Iteration is 40.\tMin distance is 0.072.\tCoverage is 0.649\n",
      "Iteration is 41.\tMin distance is 0.072.\tCoverage is 0.659\n",
      "Iteration is 42.\tMin distance is 0.072.\tCoverage is 0.665\n",
      "Iteration is 43.\tMin distance is 0.072.\tCoverage is 0.669\n",
      "Iteration is 44.\tMin distance is 0.072.\tCoverage is 0.675\n",
      "Iteration is 45.\tMin distance is 0.072.\tCoverage is 0.685\n",
      "Iteration is 46.\tMin distance is 0.072.\tCoverage is 0.691\n",
      "Iteration is 47.\tMin distance is 0.072.\tCoverage is 0.695\n",
      "Iteration is 48.\tMin distance is 0.072.\tCoverage is 0.699\n",
      "Iteration is 49.\tMin distance is 0.072.\tCoverage is 0.703\n",
      "[[384, 128, 131, 4, 262, 397, 274, 402, 280, 408, 282, 411, 422, 295, 173, 307, 52, 309, 313, 193, 331, 464, 84, 341, 473, 354, 483, 356, 102, 380], [256, 1, 197, 134, 423, 11, 46, 145, 498, 310, 221, 121, 349, 223], [377, 364, 345, 155, 348], [439, 161, 14, 79, 367, 339, 23, 243, 54, 407], [120, 453], [265, 454], [96, 290, 387, 228, 39, 74, 266, 91, 172, 47, 431, 115, 438, 347, 62, 447], [64, 416, 336, 117, 248], [59, 275], [264, 391, 229, 472], [6, 135, 8, 393, 10, 138, 394, 137, 404, 21, 151, 163, 40, 424, 43, 53, 442, 65, 330, 203, 204, 85, 470, 476, 220, 489, 235, 242, 246, 125], [0, 260, 270, 164, 169, 298, 42, 428, 49, 311, 57, 58, 451, 195, 200, 458, 76, 88, 357, 107, 495, 113, 244, 123], [208], [456, 159, 486, 263], [400, 413], [353, 97, 104, 301, 239, 496, 241, 276], [217, 236, 365, 430], [288, 224, 66, 98, 100, 69, 226, 455, 460, 493, 237, 398, 144, 337, 19, 20, 153], [129, 7, 392, 426, 306, 60], [323, 355, 5, 492, 110, 401, 499, 469, 412, 346, 315, 156, 254], [376, 212], [34, 297, 363, 366, 368, 305, 82, 308, 213, 118, 443, 157, 350], [259, 440, 425, 234, 268, 462, 80, 369, 210, 182, 375, 344, 379, 446, 383], [488, 385, 340], [450, 485, 199, 45, 334, 13, 81, 179, 183, 122], [449, 187, 149, 406], [320, 481, 3, 332, 436, 87, 215, 185, 253], [194, 329, 211, 216, 188, 29], [352, 289, 36, 165, 358, 231, 170, 12, 141, 271, 176, 17, 112, 468, 247, 94], [480, 362, 403, 51, 316, 284], [388, 70, 359, 48, 372], [232, 50, 294, 319], [93], [209, 410, 482, 114], [324, 296, 136, 466, 55, 26, 124, 190], [167, 328, 206, 432, 177, 414, 95], [399, 101, 343], [484], [37, 500, 181, 22, 218, 318], [92, 77, 78], [202, 427, 108, 174, 471], [386, 67, 325], [370, 437], [233, 435, 225], [140, 180, 28, 477, 415], [312, 300, 279], [35, 267], [184, 2], [196, 214], [321, 68, 389]]\n"
     ]
    }
   ],
   "source": [
    "oracle_results = prob_labels.select_samples(examples_to_label)\n",
    "print(oracle_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_image_list = [[image_list[prob_labels.dict_indices[\"train\"][i]] for i in sublist] for sublist in oracle_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the follow cell TWICE in a row for it to save your results properly. Some users have reported that running the cell once does not save properly in some instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HuG6YO1ZB4rW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 27.57it/s]\n"
     ]
    }
   ],
   "source": [
    "train_labeler = DataLabeler(oracle_image_list,labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images in cluster 1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7eb88ccbe948dd9ddf829e17364d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(options=('oil', 'water', 'wind'), value='oil'), HBox(children=(VBox(children=(Image(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_labeler.display_pictures_button(oracle_image_list,0,train_labeler.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at your manifest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>/deep/u/jsilberg/Brazil_hard_detections_1024_2...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path  label\n",
       "0   /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "1   /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "2   /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "3   /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "4   /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "5   /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "6   /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "7   /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "8   /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "9   /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "10  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "11  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "12  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "13  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "14  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "15  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "16  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "17  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "18  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "19  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "20  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "21  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "22  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "23  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "24  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "25  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "26  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "27  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "28  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water\n",
       "29  /deep/u/jsilberg/Brazil_hard_detections_1024_2...  water"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labeler.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell above, you can see your labels have been saved as a csv. Let's save this csv right away so nothing happens to it. Feel free to edit the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeler.df.to_csv(\"train_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells assume you will want to see how your model performs by creating a separate validation set. Here, you can label as many validation examples as you want at random, then below train a model to see how well you're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_to_label = 50\n",
    "val_image_list = [[image_list[prob_labels.dict_indices[\"val\"][i]]] for i in range(0,val_to_label)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the cell below TWICE in a row so that it saves properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 231.03it/s]\n"
     ]
    }
   ],
   "source": [
    "val_labeler = DataLabeler(val_image_list,labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images in cluster 2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c9b3c07c9841629ff2257b0d743c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(options=('oil', 'water', 'wind'), value='oil'), HBox(children=(VBox(children=(Image(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_labeler.display_pictures_button(val_image_list,0,val_labeler.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_labeler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [268]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mval_labeler\u001b[49m\u001b[38;5;241m.\u001b[39mdf\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_labeler' is not defined"
     ]
    }
   ],
   "source": [
    "val_labeler.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's save the validation manifest for safe-keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labeler.df.to_csv(\"val_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"part_4\"> Part 4: Testing your model <a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map={label: i for label, i in zip(labels_list,range(0,len(labels_list)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m ManifestData(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_df.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,label_map\u001b[38;5;241m=\u001b[39mlabels_map,transform\u001b[38;5;241m=\u001b[39m\u001b[43membeddings_transform\u001b[49m)\n\u001b[1;32m      3\u001b[0m val_data \u001b[38;5;241m=\u001b[39m ManifestData(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_df.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,label_map\u001b[38;5;241m=\u001b[39mlabels_map,transform\u001b[38;5;241m=\u001b[39membeddings_transform)\n\u001b[1;32m      4\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_data,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings_transform' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = ManifestData(\"train_df.csv\",label_map=labels_map,transform=embeddings_transform)\n",
    "val_data = ManifestData(\"val_df.csv\",label_map=labels_map,transform=embeddings_transform)\n",
    "train_loader = DataLoader(train_data,batch_size=256,num_workers=4,shuffle=True)\n",
    "val_loader = DataLoader(val_data,batch_size=1,num_workers=4,shuffle=False)\n",
    "verification_model = VerificationModel(0.001,weight_decay=.001,num_classes=len(labels_list))\n",
    "trainer = pl.Trainer(accelerator='gpu',max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sailhome/jsilberg/.local/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | convnet | ResNet           | 11.7 M\n",
      "1 | loss    | CrossEntropyLoss | 0     \n",
      "2 | val_acc | Accuracy         | 0     \n",
      "---------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.758    Total estimated model params size (MB)\n",
      "2022-11-16 14:04:06.354369: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sailhome/jsilberg/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1555: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dc360fd72a410cb1d97356182a7d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sailhome/jsilberg/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(verification_model,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
